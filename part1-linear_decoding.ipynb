{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "# Tutorial: Language: in the search of neural code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "source": [
        "Please download the relevant data and install the required packages for this tutorial by running the following 2 cells:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tZkd0CAS5efa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tZkd0CAS5efa",
        "outputId": "48e36d16-15b8-4ef5-ca5e-01187446826b"
      },
      "outputs": [],
      "source": [
        "# @title Download data\n",
        "from pathlib import Path\n",
        "\n",
        "if not Path(\"data\").exists():\n",
        "  !gdown 1jkadTwM2FbAojuwjRw_KdMpDoni7l4Xz -O data.zip\n",
        "  !unzip -q data.zip -d data\n",
        "\n",
        "!ls data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-OH7qRhK-5VF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-OH7qRhK-5VF",
        "outputId": "db0d02bc-77d1-437e-daa8-491967db36a8"
      },
      "outputs": [],
      "source": [
        "# @title Install required packages\n",
        "!pip install mne wordfreq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I0qEMF_IQ0mX",
      "metadata": {
        "cellView": "form",
        "id": "I0qEMF_IQ0mX"
      },
      "outputs": [],
      "source": [
        "# @title Util functions\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_example_data(events, raw, session):\n",
        "    \"\"\"\n",
        "    Get 3 example channels and 10 events to plot\n",
        "    \"\"\"\n",
        "    # Select 10 events to visualise\n",
        "    example_events = events.query(\"session==@session and type=='Word'\").iloc[:10]\n",
        "\n",
        "    # Get the tmin and tmax of these 10 events\n",
        "    try:\n",
        "      tmin = example_events.start.min().item() - 0.2 # 0.2 sec before word occurs\n",
        "      tmax =  example_events.start.max().item() + example_events[example_events.start==example_events.start.max()].duration.item() + 0.2\n",
        "    except:\n",
        "      tmin = example_events.start.min() - 0.2 # 0.2 sec before word occurs\n",
        "      tmax =  example_events.start.max() + example_events[example_events.start==example_events.start.max()].duration.item() + 0.2\n",
        "\n",
        "    # Get neural signal in this time window (and just 3 example channels to visualise)\n",
        "    example_channel_names = [\"MEG 0112\", \"MEG 0123\", \"MEG 0133\"]\n",
        "    neural_data = raw.copy().crop(tmin, tmax).pick(example_channel_names).get_data()\n",
        "    times = np.arange(tmin, tmax+1/raw.info[\"sfreq\"], 1/raw.info[\"sfreq\"])\n",
        "\n",
        "    return example_events, example_channel_names, neural_data, times\n",
        "\n",
        "def visualise_events(events, raw, session=\"\", plot_zipfreq=False, plot_neural=True, plot_zipf_analogue=False):\n",
        "    \"\"\"\n",
        "    Plot 10 events and 3 example channels\n",
        "    \"\"\"\n",
        "    example_events, example_channel_names, neural_data, times = get_example_data(events, raw, session)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "    yaxis = \"zipfreq\" if plot_zipfreq else \"text\"\n",
        "\n",
        "    # Plot horizontal bars for events\n",
        "    ax.barh(example_events[yaxis], example_events['duration'], left=example_events['start'],\n",
        "            height=0.4, color='skyblue', label='Events');\n",
        "\n",
        "    if plot_zipfreq: # label words\n",
        "        for _, word in example_events.iterrows():\n",
        "            ax.text(word.start, word.zipfreq, word.text)\n",
        "\n",
        "    if plot_zipf_analogue:\n",
        "        signal = np.zeros_like(times)\n",
        "\n",
        "        # Create signal from events\n",
        "        for _, row in example_events.iterrows():\n",
        "            start_idx = np.searchsorted(times, row['start'])\n",
        "            end_idx = np.searchsorted(times, row['start'] + row['duration'])\n",
        "            signal[start_idx:end_idx] = row['zipfreq']\n",
        "        ax.plot(times, signal, label=\"zipfreq\", color=\"grey\")\n",
        "\n",
        "    # Label and grid\n",
        "    ax.set_xlabel(\"Time (s)\")\n",
        "    ax.set_ylabel(yaxis.capitalize())\n",
        "    ax.set_title(\"Words and Neural Signal\")\n",
        "    ax.grid(True, axis='x')\n",
        "\n",
        "    # Twin axis for neural data\n",
        "    ax2 = ax.twinx();\n",
        "    ax.set_zorder(2)        # Main axis in front\n",
        "    ax2.set_zorder(1)       # Secondary axis in back\n",
        "    ax.patch.set_visible(False)  # Make background of ax transparent to reveal ax2\n",
        "\n",
        "    if plot_neural:\n",
        "        for n, name, color in zip(neural_data, example_channel_names, [\"#f87171\",  \"#ef4444\",   \"#b91c1c\"]):\n",
        "            ax2.plot(times, n, color=color, label=name, lw=0.5)\n",
        "        ax2.set_yticks([])  # Hide secondary y-axis ticks\n",
        "        ax2.set_ylabel(\"Neural Activity (a.u.)\")\n",
        "\n",
        "    # Combine legends\n",
        "    lines1, labels1 = ax.get_legend_handles_labels()\n",
        "    labels1 = [\"Words\"]\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    loc = \"lower right\"\n",
        "    ax2.legend(lines1 + lines2, labels1 + labels2, loc=loc)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "3",
        "outputId": "ca3edf19-5287-4087-8e12-d4fbcdfd3864"
      },
      "outputs": [],
      "source": [
        "#@title Intro\n",
        "from IPython.display import display, HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Main profile image path\n",
        "main_path = \"images/profile_evanson.png\"\n",
        "\n",
        "# Two small logos paths\n",
        "logo1_path = \"images/Meta_lockup_positive primary_RGB.png\" # Replace with actual paths\n",
        "logo2_path = \"images/rothschild_logo.png\"\n",
        "\n",
        "# Encode images in base64\n",
        "def encode_img(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "main_img = encode_img(main_path)\n",
        "logo1_img = encode_img(logo1_path)\n",
        "logo2_img = encode_img(logo2_path)\n",
        "\n",
        "html = f\"\"\"\n",
        "<div style=\"display: flex; align-items: flex-start; justify-content: space-between;\">\n",
        "    <!-- Left side: profile image and text -->\n",
        "    <div style=\"display: flex; align-items: flex-start;\">\n",
        "        <img src=\"data:image/png;base64,{main_img}\" width=\"200\" style=\"margin-right: 20px;\"/>\n",
        "        <div style=\"font-size: 24px; font-weight: bold; margin-bottom: 8px;\">\n",
        "            <b>Part 1: Linear Decoding</b><br>\n",
        "            <div style=\"font-size: 18px; line-height: 1.5; font-weight: normal;\">\n",
        "                Linnea Evanson, PhD<br>\n",
        "                Postdoc at Rothschild Foundation Hospital. Previously @MetaAI as a Research Intern.<br><br>\n",
        "                Relevant <a href=\"https://scontent-cdg4-2.xx.fbcdn.net/v/t39.2365-6/497635895_1416828025978405_6687721506010334726_n.pdf?_nc_cat=100&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=hh5qWVa8BS0Q7kNvwHMdq2u&_nc_oc=AdkioyBW072oV6OwbnYxTrLXQqHbGLHn6MsTm5pP79SVAouRDBwy7j4ArLTsjsmuR7U&_nc_zt=14&_nc_ht=scontent-cdg4-2.xx&_nc_gid=61wrENL-7sXi0dWEn9jFag&oh=00_AfXL72-uPD8uIkyrVPbQCh2eE0mqmLzCVERKiFc5r7pCjw&oe=689BB1A4\" target=\"_blank\">paper</a>: <br>\n",
        "                \"Emergence of language in the developing brain\" (Evanson et al, 2025)<br>\n",
        "                An sEEG study in children as young as 2 years old, investigating representations of language through de/encoding analyses.<br><br>\n",
        "                Keep in touch: <a href=\"https://x.com/EvansonLinnea\" target=\"_blank\">X</a>,\n",
        "                               <a href=\"https://www.linkedin.com/in/linnea-evanson/\" target=\"_blank\">Linkedin</a>,\n",
        "                               <a href=\"https://scholar.google.com/citations?user=VgTpOTIAAAAJ&hl=en\" target=\"_blank\">Scholar</a>,\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Right side: two small logos -->\n",
        "    <div style=\"display: flex; flex-direction: column; gap: 10px; margin-left: 20px;\">\n",
        "    <div style=\"display: flex; flex-direction: column; gap: 10px; margin-left: 20px; align-items: center;\">\n",
        "\n",
        "        <img src=\"data:image/png;base64,{logo1_img}\" width=\"200\" style=\"object-fit: contain;\" />\n",
        "        <img src=\"data:image/png;base64,{logo2_img}\" width=\"100\" style=\"object-fit: contain;\" />\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "source": [
        "### Goal of this tutorial\n",
        "\n",
        "**Question:** What kind of information does the brain represent? \\\n",
        "For example, does the brain represent word information? What about word frequency information?\n",
        "\n",
        "**Solution**: decoding allows us to investigate the representations present in neural data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "source": [
        "### Overview of this tutorial\n",
        "\n",
        "Part 1) Linear decoding over time (30 mins) \\\n",
        "Part 2) Modular experimental design and caching (30 mins) \\\n",
        "Part 3) Deep decoding (30 mins)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "source": [
        "### What is decoding?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "source": [
        "We fit a model $f$, given $x$ to predict $y$. \\\n",
        "$x$ is the neural data and $y$ is the feature describing the stimulus. \\\n",
        "The model $f$ could be linear (eg. a ridge regression) or deep (a conv net, a transformer, whatever you like).\n",
        "\n",
        "We evaluate the model by finding the correlation between the feature predicted by the model ($y_{pred}$) and the true feature ($y$).\n",
        "\n",
        "![decoding](https://github.com/lucyzmf/NeuralDecoding-CCN2025/blob/main/images/part1_decoding.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "source": [
        " ### What can decoding tell us?\n",
        "- Which features are represented in the brain.\n",
        "- If they are linearly decodable.\n",
        "- The dynamics of these representations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "source": [
        "### How do we investigate dynamics?\n",
        "\n",
        "We can fit and evaluate such a model over different timesteps, to see how well a representation is decoded at each timestep.\n",
        "\n",
        "For example, in \"Emergence of language in the developing brain\" (Evanson et al, 2025) https://ai.meta.com/research/publications/emergence-of-language-in-the-developing-brain/, \\\n",
        "we presented an audiobook to participants and then investigated neural representations around the onset of each word. \\\n",
        "\n",
        "We fit one linear regression at each timestep, from [-2, 3s], we here plot the correlation value at each timestep. \\\n",
        "We do this seperately for a variety of features ($y$), such as nouns (where $y$ takes value 0 when a noun is present, and 0 when it is not present) and verbs.\n",
        "\n",
        "We observe that the brain does represent word information and that information is present for around 1.5 seconds after the word onset (t=0).\n",
        "\n",
        "![word decoding](https://github.com/lucyzmf/NeuralDecoding-CCN2025/blob/main/images/part1_word_decoding.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "source": [
        "Example output for Part 1:\n",
        "\n",
        "![word decoding example](https://github.com/lucyzmf/NeuralDecoding-CCN2025/blob/main/images/part1_example_output.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "source": [
        "# Part 1: Linear decoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "source": [
        "Contents:\n",
        "1. Load and explore the data\n",
        "2. Preparing the data\n",
        "3. Decoding\n",
        "4. Structuring the code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "source": [
        "If you haven't already done so, download the relevant data to the colab instance (first cell in this notebook)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "source": [
        "### 1. Load and explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UzfBxfGZ9FGU",
      "metadata": {
        "id": "UzfBxfGZ9FGU"
      },
      "source": [
        "In this tutorial we are using a subset of the data presented in \"LibriBrain: Over 50 Hours of Within-Subject MEG to Improve Speech Decoding Methods at Scale\" (Özdogan et al, 2025, https://arxiv.org/abs/2506.02098).\n",
        "\n",
        "Key facts:\n",
        "- MEG recordings\n",
        "- Naturalistic language stimuli (Sherlock homes audiobooks)\n",
        "- Publically available (https://huggingface.co/datasets/pnpl/LibriBrain)\n",
        "- Now part of a language decoding competition: https://neural-processing-lab.github.io/2025-libribrain-competition/.\n",
        "- Here we analyse only a subset of this dataset!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17",
        "outputId": "5e73f63f-95d7-4c03-8182-40eb446ba6d8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import mne\n",
        "import matplotlib.pyplot as plt\n",
        "%xmode Plain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18",
      "metadata": {
        "id": "18"
      },
      "outputs": [],
      "source": [
        "preproc_path = Path(\"data/\")\n",
        "assert preproc_path.exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19",
      "metadata": {
        "id": "19"
      },
      "source": [
        "What's in the data folder?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20",
        "outputId": "985afbf6-773a-49a9-a0e3-e03ce13bbb2f"
      },
      "outputs": [],
      "source": [
        "[i.name for i in preproc_path.glob(\"*\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21",
      "metadata": {
        "id": "21"
      },
      "source": [
        "We see the data seems to be organised into different sessions. Neural data is stored in .fif files, and information about the events (the stimulus presented) is in a csv.\\\n",
        "Let's check out the events dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "22",
        "outputId": "d6d21031-9374-4be6-c25d-49167e382e1c"
      },
      "outputs": [],
      "source": [
        "events = pd.read_csv(preproc_path / \"events.csv\").drop(columns=\"Unnamed: 0\")\n",
        "events.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23",
      "metadata": {
        "id": "23"
      },
      "source": [
        "We see there are 'Meg' events and 'Word' events.\n",
        "All the words that were presented to the participant are listed for each session. Let's checkout some statistics about the events: Number of sessions? Number of words presented?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24",
        "outputId": "8d0e7318-bdf9-4653-a16c-2673b0cf5ae0"
      },
      "outputs": [],
      "source": [
        "print(\"n session (number of neural files):\", events.session.nunique(),\n",
        "\"\\ntypes of events:\", events.type.unique(),\n",
        "\"\\nn words per session:\", events.query(\"type=='Word'\").groupby(\"session\").text.count().mean(),\n",
        "\"\\naverage duration of words:\", events.query(\"type=='Word'\").duration.mean(), \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25",
      "metadata": {
        "id": "25"
      },
      "source": [
        "Let's load an example meg file and plot the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26",
        "outputId": "ba5d0d39-915e-4cdd-98b2-ee740c3c2517"
      },
      "outputs": [],
      "source": [
        "session = \"LibriBrain2025_subject-0_session-1_run-1_task-Sherlock1\"\n",
        "raw = mne.io.read_raw(preproc_path / f\"{session}_preproc.fif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "27",
        "outputId": "acf57f45-a71d-4d00-e179-bb21ade3ca2d"
      },
      "outputs": [],
      "source": [
        "raw.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28",
      "metadata": {
        "id": "28"
      },
      "source": [
        "How do the events line up with the neural responses? Let's visualise this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "29",
        "outputId": "5dd46f8a-e341-497b-bae1-5fff1b732a3e"
      },
      "outputs": [],
      "source": [
        "visualise_events(events, raw, session=session)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30",
      "metadata": {
        "id": "30"
      },
      "source": [
        "### 2. Preparing the data (x: neural and y: feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31",
      "metadata": {
        "id": "31"
      },
      "source": [
        "Now that we understand how our dataset is structured it's time to prepare our inputs. We need to\n",
        "\n",
        "A) Filter the neural data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32",
        "outputId": "061c1999-aa5d-41be-e17e-10dcb70ac5df"
      },
      "outputs": [],
      "source": [
        "def prepare_neuro(session):\n",
        "    \"\"\"\n",
        "    Relevant mne tutorial:\n",
        "    https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html\n",
        "\n",
        "    \"\"\"\n",
        "    file= Path(preproc_path) / f\"{session}_preproc.fif\"\n",
        "\n",
        "    if file.exists():\n",
        "        raw = mne.io.read_raw(file)\n",
        "\n",
        "    else:\n",
        "        fmin = 0.1\n",
        "        fmax = 40.\n",
        "        freq = 80.\n",
        "\n",
        "        original_file = preproc_path / f\"{session}.fif\" # original file\n",
        "        raw = mne.io.read_raw(original_file)\n",
        "        raw = raw.pick(picks=[\"meg\"]) # don't want to analyse misc\n",
        "\n",
        "        # band pass filter\n",
        "        raw = raw.filter(fmin, fmax)\n",
        "\n",
        "        # downsample\n",
        "        if freq != raw.info[\"sfreq\"]:\n",
        "            raw = raw.resample(freq)\n",
        "\n",
        "        # save\n",
        "        raw.save(file, overwrite=False)\n",
        "\n",
        "    return raw\n",
        "\n",
        "session =  \"LibriBrain2025_subject-0_session-1_run-1_task-Sherlock1\"\n",
        "raw = prepare_neuro(session)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33",
      "metadata": {
        "id": "33"
      },
      "source": [
        "B) Compute the feature of interest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34",
      "metadata": {
        "id": "34"
      },
      "source": [
        "Rather than decoding the word itself as a classification task, we want to decode a feature characterising some aspect of the words. \\\n",
        "Here we choose zipf frequency: the logarithm of the frequency of words in natural language.    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35",
        "outputId": "34cc85fa-0257-4664-9321-9569cace4d8b"
      },
      "outputs": [],
      "source": [
        "from wordfreq import zipf_frequency\n",
        "\n",
        "def get_word_freq(word: str) -> float:\n",
        "    return zipf_frequency(word.lower(), 'en')\n",
        "\n",
        "events = pd.read_csv(preproc_path / \"events.csv\")\n",
        "\n",
        "# Select the words in the relevant session\n",
        "words = events[(events['type'] == 'Word') & (events['session'] == session)].dropna().reset_index(drop=True)\n",
        "words['zipfreq'] = words.text.apply(get_word_freq)\n",
        "\n",
        "\n",
        "feature_array = words.zipfreq.values[:, np.newaxis]\n",
        "print(\"\\nfeature_array: (n_words, n_dims)\", feature_array.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36",
      "metadata": {
        "id": "36"
      },
      "source": [
        "For zipfreq ndims=1, but for other features (eg. a word embedding) ndims could be > 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37",
      "metadata": {
        "id": "37"
      },
      "source": [
        "What does this zipfreq look like for our example sentence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "38",
        "outputId": "5aa1ed45-ce30-4084-fde9-b7dfb8adb8c1"
      },
      "outputs": [],
      "source": [
        "visualise_events(words.iloc[:10], raw, session=session, plot_zipfreq=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "39",
        "outputId": "6a32f1c6-d1d6-483d-8f88-442d3ca81a72"
      },
      "outputs": [],
      "source": [
        "visualise_events(words.iloc[:10], raw, session=session, plot_zipfreq=True, plot_neural=False, plot_zipf_analogue=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40",
      "metadata": {
        "id": "40"
      },
      "source": [
        "C) We need to segment the neural data around the onset of each word.\n",
        "\n",
        "We set a window (tmin, tmax) around each word to segment. \\\n",
        "The mne.Epochs object segments the neural data, and stacks those segments (1 per word)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kYNQdQlOxzMU",
      "metadata": {
        "id": "kYNQdQlOxzMU"
      },
      "source": [
        "**Question:** What would be an appropriate time window to decode over?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41",
      "metadata": {
        "id": "41"
      },
      "outputs": [],
      "source": [
        "## Set the time window (around word onset) to segment the neural data\n",
        "tmin = -0.5\n",
        "tmax = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42",
      "metadata": {
        "id": "42"
      },
      "outputs": [],
      "source": [
        "# Get word onsets in samples\n",
        "word_onsets = np.ones((len(words), 3), dtype=int) # mne.epochs expects events of shape (n_events, 3) but we are only interested in the first column here -> set the rest to 1\n",
        "word_onsets[:, 0] = words.start *raw.info[\"sfreq\"] # first column must contain the onset of each event (word) in samples\n",
        "\n",
        "# Segment\n",
        "segments = mne.Epochs(\n",
        "    raw,\n",
        "    word_onsets,\n",
        "    metadata=words,\n",
        "    event_repeated=\"drop\",\n",
        "    tmin=tmin,\n",
        "    tmax=tmax,\n",
        ")\n",
        "\n",
        "# from mne to numpy\n",
        "neuro_array = segments.get_data()\n",
        "\n",
        "print(\"\\n\\nneuro_array: n_segments (n_words), n_channels, n_times\", neuro_array.shape)\n",
        "\n",
        "# Get the words aligned with the mne segments\n",
        "feature_array = segments.metadata[\"zipfreq\"].values[:, np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pZyduVmvyF1h",
      "metadata": {
        "id": "pZyduVmvyF1h"
      },
      "source": [
        "**Question:** Does our segmented neural data and feature (zipfreq) share any dimension? What does that dimension represent? \\\n",
        "Write an assert to verify that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J0J8FYXSzPZv",
      "metadata": {
        "cellView": "form",
        "id": "J0J8FYXSzPZv"
      },
      "outputs": [],
      "source": [
        "#@title Answer\n",
        "assert neuro_array.shape[0] == feature_array.shape[0] # same number of words\n",
        "\n",
        "print(\"neuro_array: n_words, n_channels, n_times\", neuro_array.shape, \"\\nfeature_array: n_words, n_dims\", feature_array.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45",
      "metadata": {
        "id": "45"
      },
      "source": [
        "What does this segmented neural data look like?  ...we see activation in response to a word (presented at t=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46",
      "metadata": {
        "id": "46"
      },
      "outputs": [],
      "source": [
        "segments.average().plot(); # we average over all the words, plotting one line per channel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47",
      "metadata": {
        "id": "47"
      },
      "source": [
        "### 3. Decoding\n",
        "\n",
        "Now that we've prepared everything, it's time to fit a model given neural data ($X$), to predict our feature of interest ($y$). We will then evaluate the performance of this model by computing the correlation between the true ($y$) and predicted ($y_{pred}$) feature.\n",
        "\n",
        "$y_{pred} = f(X) $ \\\n",
        "$R = corr(y, y_{pred})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48",
      "metadata": {
        "id": "48"
      },
      "source": [
        "In order to fairly evaluate the model we use cross validation (cv) splits: fitting the model on a portion (k) of the data, and evaluating on the rest (1-k). \\\n",
        "We use Ridge from sklearn to implement this.\n",
        "\n",
        "**Note! In order to get a decoding curve over time, we fit and evaluate a model per timestep.** \\\n",
        "We iterate over timesteps (t), selecting the neural data at that timestep: X[:, :, t]. \\\n",
        "Meaning x will be of shape n_words, n_channels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49",
      "metadata": {
        "id": "49"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50",
      "metadata": {
        "id": "50"
      },
      "source": [
        "Remind ourselves the dimensions of our X (neuro_array) and y (feature_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51",
      "metadata": {
        "id": "51"
      },
      "outputs": [],
      "source": [
        "assert neuro_array.shape[0] == feature_array.shape[0] # same number of words\n",
        "print(\"neuro_array: n_words, n_channels, n_times\", neuro_array.shape, \"\\nfeature_array: n_words, n_dims\", feature_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52",
      "metadata": {
        "id": "52"
      },
      "outputs": [],
      "source": [
        "n_folds = 2  # number of cv splits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xyxBS50Uzx7O",
      "metadata": {
        "id": "xyxBS50Uzx7O"
      },
      "source": [
        "**Question:** what is the expected dimension of the correlation array r in the following loop? -> Initialise r_scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iYn7DUfW0TEt",
      "metadata": {
        "cellView": "form",
        "id": "iYn7DUfW0TEt"
      },
      "outputs": [],
      "source": [
        "#@title Answer\n",
        "# r_scores = np.zeros((cv.n_splits, n_times, n_dims))  # as we are looping over cv splits, timesteps, and then find a correlation per dimension of the feature (here n_dims=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53",
      "metadata": {
        "id": "53"
      },
      "outputs": [],
      "source": [
        "n_words, n_channels, n_times = neuro_array.shape\n",
        "n_words, n_dims = feature_array.shape\n",
        "\n",
        "# init model\n",
        "model = make_pipeline(StandardScaler(), Ridge(alpha=1e4))\n",
        "\n",
        "# init cross validation\n",
        "cv = KFold(n_folds, shuffle=False)  # shuffle false to keep overlapping segments in same cv split\n",
        "\n",
        "# experiment loop\n",
        "r_scores = np.zeros((cv.n_splits, n_times, n_dims))\n",
        "for split, (train, test) in enumerate(cv.split(neuro_array)):\n",
        "    for t in trange(n_times, desc=f\"split {split}/{cv.n_splits}\"):\n",
        "        model.fit(X=neuro_array[train, :, t], y=feature_array[train])\n",
        "        preds = model.predict(X=neuro_array[test, :, t])\n",
        "        preds = preds[:, np.newaxis] if preds.ndim==1 else preds\n",
        "\n",
        "        for d in range(n_dims):\n",
        "            r_scores[split, t, d] = pearsonr(\n",
        "                preds[:, d],\n",
        "                feature_array[test, d]\n",
        "            ).statistic\n",
        "# mean across splits\n",
        "r = r_scores.mean(0)\n",
        "# mean across feature dims (here only 1 dim)\n",
        "r = r.mean(1)\n",
        "\n",
        "print(\"\\nr shape: (n_times)\", r.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54",
      "metadata": {
        "id": "54"
      },
      "source": [
        "### Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55",
      "metadata": {
        "id": "55"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56",
      "metadata": {
        "id": "56"
      },
      "outputs": [],
      "source": [
        "def plot_results(times, r):\n",
        "    results = pd.DataFrame(dict(times=times, r=r))\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.lineplot(results, x=\"times\", y=\"r\", ax=ax)\n",
        "    ax.axhline(0, color=\"k\", ls=\"--\", zorder=-5)\n",
        "    ax.axvline(0, color=\"grey\", ls=\"--\", zorder=-5, label=\"Event onset\")\n",
        "    ax.set_title(\"Decoding zipfreq over time\")\n",
        "    ax.set_ylabel(\"Correlation\")\n",
        "    ax.set_xlabel(\"Times relative to word onset (s)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_results(segments.times, r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GnrSw6JH5uKX",
      "metadata": {
        "id": "GnrSw6JH5uKX"
      },
      "source": [
        "**Question:** How could we improve these decoding scores?\n",
        "Here we only use 1 session - how can we easily structure our code to use all 10 sessions?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59",
      "metadata": {
        "id": "59"
      },
      "source": [
        "### 4. Structuring the code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61",
      "metadata": {
        "id": "61"
      },
      "source": [
        "Rather than using functions we will use classes which allow us to build cleaner and more modular code at scale.\n",
        "\n",
        "Here we construct 4 classes:\\\n",
        "1) class Neuro - gets the neuro_array for 1 session\\\n",
        "2) class Feature - gets the feature_array (here zipfreq) for 1 session\\\n",
        "3) class Data - gets Neuro and Feature (aggregates them over multiple sessions) and returns neuro_array, feature_array\\\n",
        "4) class Experiment - gets Data and fits the regression\n",
        "\n",
        "Keeping our code modular in this way allows us to easily scale to fitting a model on data from multiple sessions as once, include other types of features (besides zipfreq) or test different neural preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62",
      "metadata": {
        "id": "62"
      },
      "outputs": [],
      "source": [
        "import pydantic\n",
        "import typing as tp\n",
        "\n",
        "class Neuro(pydantic.BaseModel):\n",
        "\n",
        "    preproc_path: Path\n",
        "    fmin: float = 0.1\n",
        "    fmax: float = 40.\n",
        "    freq: float = 80.\n",
        "    tmin: float = -.5\n",
        "    tmax: float = 1.\n",
        "\n",
        "    def prepare_neuro(self, session: str) -> mne.io.Raw:\n",
        "\n",
        "        \"\"\" Load the raw neuro data and filter \"\"\"\n",
        "\n",
        "        file= Path(self.preproc_path) / f\"{session}_preproc.fif\"\n",
        "\n",
        "        if file.exists():\n",
        "            raw = mne.io.read_raw(file, verbose=\"ERROR\")\n",
        "\n",
        "        else:\n",
        "            fmin = self.fmin\n",
        "            fmax = self.fmax\n",
        "            freq = self.freq\n",
        "\n",
        "            original_file = self.preproc_path / f\"{session}.fif\"  # original file\n",
        "            raw = mne.io.read_raw(original_file)\n",
        "            raw = raw.pick(picks=[\"meg\"]) # don't want to analyse misc\n",
        "\n",
        "            # band pass filter\n",
        "            raw = raw.filter(fmin, fmax)\n",
        "\n",
        "            # downsample\n",
        "            if freq != raw.info[\"sfreq\"]:\n",
        "                raw = raw.resample(freq)\n",
        "\n",
        "        return raw\n",
        "\n",
        "    def __call__(self, session:str) -> tuple[np.ndarray, list[str]]:\n",
        "\n",
        "        \"\"\" Segment the neural data around words \"\"\"\n",
        "\n",
        "        raw = self.prepare_neuro(session)\n",
        "\n",
        "        events = pd.read_csv(self.preproc_path / \"events.csv\")\n",
        "\n",
        "        # Select the words in the relevant session\n",
        "        words = events[(events['type'] == 'Word') & (events['session'] == session)].dropna().reset_index(drop=True)\n",
        "\n",
        "        # Get word onsets in samples\n",
        "        word_onsets = np.ones((len(words), 3), dtype=int) # mne.epochs expects events of shape (n_events, 3) but we are only interested in the first column here -> set the rest to 0\n",
        "        word_onsets[:, 0] = words.start *raw.info[\"sfreq\"] # first column must contain the onset of each event (word) in samples\n",
        "\n",
        "        # Segment\n",
        "        segments = mne.Epochs(\n",
        "            raw,\n",
        "            word_onsets,\n",
        "            metadata=words,\n",
        "            event_repeated=\"drop\",\n",
        "            tmin=self.tmin,\n",
        "            tmax=self.tmax,\n",
        "            verbose=\"ERROR\"\n",
        "        )\n",
        "\n",
        "        # from mne to numpy\n",
        "        neuro_array = segments.get_data(verbose=\"ERROR\")\n",
        "\n",
        "        n_words, n_channels, n_times = neuro_array.shape\n",
        "        words = segments.metadata['text']\n",
        "\n",
        "        return neuro_array, words\n",
        "\n",
        "\n",
        "class Feature(pydantic.BaseModel):\n",
        "    feature: tp.Literal['zipf_frequency', 'word_embedding']\n",
        "    _model = None\n",
        "\n",
        "    def __call__(self, word: str) -> list[float]:\n",
        "\n",
        "        \" Compute word frequency or word embedding for a single word \"\n",
        "\n",
        "        if self.feature == 'zipf_frequency':\n",
        "            return [zipf_frequency(word, 'en')]\n",
        "        else:\n",
        "            if self._model is None:\n",
        "                self._model = spacy.load(\"en_core_web_sm\")\n",
        "            word_embedding = self._model(word)[0].emb_\n",
        "            return word_embedding.tolist()\n",
        "\n",
        "\n",
        "class Data(pydantic.BaseModel):\n",
        "    neuro: Neuro\n",
        "    feature: Feature\n",
        "    n_sessions: int = 1\n",
        "\n",
        "    def __call__(self) -> tuple[np.ndarray, np.ndarray]:\n",
        "\n",
        "        \"\"\" concatenate neural data and feature over multiple sessions \"\"\"\n",
        "\n",
        "        print(\"Preparing data\")\n",
        "\n",
        "        # get data\n",
        "        neuro_array = []\n",
        "        words = []\n",
        "\n",
        "        sessions = [i.name.split(\"_preproc\")[0] for i in sorted(list(self.neuro.preproc_path.glob(\"*.fif\")))] # neuro files available in path\n",
        "        if self.n_sessions > len(sessions):\n",
        "            raise ValueError(f\"You requested {self.n_sessions} but there are only {len(sessions)} available.\")\n",
        "\n",
        "        for session in sessions[:self.n_sessions]:\n",
        "            session_neuro_array, session_words = self.neuro(session)\n",
        "            neuro_array.append(session_neuro_array)\n",
        "            words.extend(session_words)\n",
        "        neuro_array = np.concatenate(neuro_array, 0)\n",
        "\n",
        "        # compute embedding\n",
        "        feature_array = np.asarray([self.feature(word) for word in words])\n",
        "        n_words, n_dims = feature_array.shape\n",
        "        return neuro_array, feature_array\n",
        "\n",
        "\n",
        "class Experiment(pydantic.BaseModel):\n",
        "    data: Data\n",
        "    n_folds: int = 5\n",
        "\n",
        "    def run(self) -> np.ndarray:\n",
        "\n",
        "        \"\"\" fit a linear decoding model \"\"\"\n",
        "\n",
        "        print(f\"Decoding {self.data.feature.feature} from {self.data.n_sessions} sessions\")\n",
        "\n",
        "        neuro_array, feature_array = self.data()\n",
        "        n_words, n_channels, n_times = neuro_array.shape\n",
        "        n_words, n_dims = feature_array.shape\n",
        "\n",
        "        print(\"Fitting model\")\n",
        "        # init model\n",
        "        model = make_pipeline(StandardScaler(), Ridge(alpha=1e4))\n",
        "\n",
        "        # init cross validation\n",
        "        cv = KFold(self.n_folds, shuffle=False)\n",
        "\n",
        "        # experiment loop\n",
        "        r_scores = np.zeros((cv.n_splits, n_times, n_dims))\n",
        "        for split, (train, test) in enumerate(cv.split(neuro_array)):\n",
        "            for t in trange(n_times, desc=f\"split {split}/{cv.n_splits}\"):\n",
        "                model.fit(X=neuro_array[train, :, t], y=feature_array[train])\n",
        "                preds = model.predict(X=neuro_array[test, :, t])\n",
        "                preds = preds[:, np.newaxis] if preds.ndim==1 else preds\n",
        "\n",
        "                for d in range(n_dims):\n",
        "                    r_scores[split, t, d] = pearsonr(\n",
        "                        preds[:, d],\n",
        "                        feature_array[test, d]\n",
        "                    ).statistic\n",
        "        # mean across splits\n",
        "        r = r_scores.mean(0)\n",
        "        # mean across feature dimensions\n",
        "        r = r.mean(1)\n",
        "        return r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ak5bK5jR5NIC",
      "metadata": {
        "id": "ak5bK5jR5NIC"
      },
      "source": [
        "So what exactly are the advantages of structuring our code in classes like this?\n",
        "\n",
        "How would we run the same decoding analysis we've done above using these classes?\n",
        "\n",
        "To answer these questions let's move to Part 2!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "weIH_wc2pawD",
      "metadata": {
        "id": "weIH_wc2pawD"
      },
      "source": [
        "Click here for Part 2:\n",
        "https://colab.research.google.com/github/lucyzmf/NeuralDecoding-CCN2025/blob/main/part2-exca.ipynb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "neuralset",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
