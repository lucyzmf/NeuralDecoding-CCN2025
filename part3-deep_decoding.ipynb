{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdDUQwc5QhrH"
      },
      "source": [
        "# Part 3: Decoding with deep learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "pTeZm9a8Frxu",
        "outputId": "8af9f107-f991-4dd9-b6c5-c622102bc5bd"
      },
      "outputs": [],
      "source": [
        "# @title Intro\n",
        "from IPython.display import display, HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Main profile image path\n",
        "main_path = \"images/profile_banville.jpg\"\n",
        "\n",
        "# Two small logos paths\n",
        "logo1_path = \"images/Meta_lockup_positive primary_RGB.png\" # Replace with actual paths\n",
        "\n",
        "# Encode images in base64\n",
        "def encode_img(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "main_img = encode_img(main_path)\n",
        "logo1_img = encode_img(logo1_path)\n",
        "\n",
        "html = f\"\"\"\n",
        "<div style=\"display: flex; align-items: flex-start; justify-content: space-between;\">\n",
        "    <!-- Left side: profile image and text -->\n",
        "    <div style=\"display: flex; align-items: flex-start;\">\n",
        "        <img src=\"data:image/png;base64,{main_img}\" width=\"200\" style=\"margin-right: 20px;\"/>\n",
        "        <div style=\"font-size: 24px; font-weight: bold; margin-bottom: 8px;\">\n",
        "            <b>Part 3: Decoding with deep learning</b><br>\n",
        "            <div style=\"font-size: 18px; line-height: 1.5; font-weight: normal;\">\n",
        "                Hubert Banville, PhD<br>\n",
        "                Research Scientist at Meta FAIR.<br><br>\n",
        "                Relevant <a href=\"https://arxiv.org/abs/2501.15322\" target=\"_blank\">paper</a>: <br>\n",
        "                \"Scaling laws for decoding images from brain activity\"<br><br>\n",
        "                Keep in touch:\n",
        "                    <a href=\"https://hubertjb.github.io/\" target=\"_blank\">Website</a>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Right side: two small logos -->\n",
        "    <div style=\"display: flex; flex-direction: column; gap: 10px; margin-left: 20px;\">\n",
        "    <div style=\"display: flex; flex-direction: column; gap: 10px; margin-left: 20px; align-items: center;\">\n",
        "\n",
        "        <img src=\"data:image/png;base64,{logo1_img}\" width=\"200\" style=\"object-fit: contain;\" />\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01KvvndTF2Zm"
      },
      "source": [
        "In this third part, we will build upon previous sections to construct a flexible deep learning pipeline to decode word embeddings from MEG data.\n",
        "\n",
        "**Contents**:\n",
        "\n",
        "0. Why decoding with deep learning?\n",
        "1. Preparing dataloaders\n",
        "2. Building the model\n",
        "3. Preparing the training loop\n",
        "4. Training the model\n",
        "5. Visualizing the results\n",
        "6. Leveraging exca for large-scale experimentation and next steps\n",
        "\n",
        "[Insert visual summary]\n",
        "\n",
        "*This notebook is inspired by this tutorial on [deep learning for sleep staging from EEG](https://github.com/hubertjb/dl-eeg-tutorial).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bDfN7KATdCQ"
      },
      "source": [
        "‚ö†Ô∏è **Before starting, make sure you're on a GPU instance for faster training!** ‚ö†Ô∏è\n",
        "\n",
        "> If running on Google Colab, please request a GPU runtime by clicking `Runtime/Change runtime type` in the top bar menu, then selecting 'T4 GPU' under 'Hardware accelerator'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZK2rYtCSgEl",
        "outputId": "bdbaa04c-31c3-4cc4-ce65-5ca1193bccb7"
      },
      "outputs": [],
      "source": [
        "# Identify whether a CUDA-enabled GPU is available\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if device == \"cuda\":\n",
        "    msg ='CUDA-enabled GPU found. Training should be faster.'\n",
        "else:\n",
        "    msg = (\n",
        "        \"No GPU found. Training will be carried out on CPU, which might be \"\n",
        "        \"slower.\\n\\nIf running on Google Colab, you can request a GPU runtime by\"\n",
        "        \" clicking\\n`Runtime/Change runtime type` in the top bar menu, then \"\n",
        "        \"selecting \\'T4 GPU\\'\\nunder \\'Hardware accelerator\\'.\"\n",
        "    )\n",
        "print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HDaKnwhTFSx",
        "outputId": "295124cc-3a9f-45fe-c038-f4d30c969cab"
      },
      "outputs": [],
      "source": [
        "#@title ‚ñ∂Ô∏è Let's download the data in case it's not yet available\n",
        "\n",
        "if not Path(\"data\").exists():\n",
        "  !gdown 1jkadTwM2FbAojuwjRw_KdMpDoni7l4Xz -O data.zip\n",
        "  !unzip -q data.zip -d data\n",
        "\n",
        "!ls data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SadqlJ02D3Lo",
        "outputId": "fd7954dd-773f-42e3-dc4d-e46309ae6546"
      },
      "outputs": [],
      "source": [
        "#@title ‚ñ∂Ô∏è Install additional required packages for colab\n",
        "!pip install lightning==2.5.2 --no-deps  # to avoid installing another torch version than default one on colab\n",
        "!pip install pytorch-lightning --no-deps\n",
        "!pip install torchmetrics --no-deps\n",
        "!pip install lightning-utilities\n",
        "!pip install torchinfo\n",
        "!pip install exca\n",
        "!pip install mne\n",
        "!pip install spacy\n",
        "!pip install wordfreq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Vnj2BkQhrK"
      },
      "source": [
        "## 0. Why should we look beyond linear models?\n",
        "\n",
        "Linear models are fast to train, easy to interpret, and yield good performance. Why should we look into more complicated deep learning models?\n",
        "\n",
        "Some reasons include:\n",
        "\n",
        "1. Enables learning powerful **non-linear features end-to-end** -> often yields better decoding performance\n",
        "2. Facilitate **cross-subject learning** by using subject-specific layers or embeddings\n",
        "3. Allows using **custom learning objectives** such as contrastive losses (e.g. CLIP) to align predictions and modality (word) embeddings\n",
        "\n",
        "Successful applications of deep models to M/EEG decoding tasks from our team include:\n",
        "* üí¨ [Speech decoding (D√©fossez et al., 2023)](https://www.nature.com/articles/s42256-023-00714-5)\n",
        "* üñºÔ∏è [Image decoding (Benchetrit et al., 2023)](https://arxiv.org/abs/2310.19812)\n",
        "* üìÑ [Word decoding (d'Ascoli et al., 2024)](https://arxiv.org/abs/2412.17829)\n",
        "* ‚å®Ô∏è [Typing decoding (L√©vy et al., 2025)](https://arxiv.org/abs/2502.17480)\n",
        "\n",
        "[Add image from one of the papers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMzf8M0GQhrK"
      },
      "source": [
        "### In this notebook\n",
        "\n",
        "Below, we will build everything we need to train a deep learning model on the word embedding decoding task, including:\n",
        "\n",
        "- Preparing the dataloaders\n",
        "- Building the deep learning model\n",
        "- Preparing the training loop\n",
        "- Training the model\n",
        "- Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD9B9MWEXVQ0"
      },
      "outputs": [],
      "source": [
        "# Set some paths to locate the data and cache/save results\n",
        "DATA_DIR = Path(\"data\")\n",
        "CACHE_DIR = Path(\"cache\")\n",
        "RESULTS_DIR = Path(\"results\")\n",
        "\n",
        "assert DATA_DIR.exists()\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BDPcbeMQhrL"
      },
      "outputs": [],
      "source": [
        "#@title ‚ñ∂Ô∏è Run this to redefine utilities from parts 1 and 2\n",
        "\n",
        "import typing as tp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydantic\n",
        "import spacy\n",
        "from exca import MapInfra, TaskInfra\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from wordfreq import zipf_frequency\n",
        "\n",
        "\n",
        "class Neuro(pydantic.BaseModel):\n",
        "\n",
        "    model_config = pydantic.ConfigDict(extra=\"forbid\")\n",
        "\n",
        "    preproc_path: Path\n",
        "    fmin: float = 0.1\n",
        "    fmax: float = 40.\n",
        "    freq: float = 80.\n",
        "\n",
        "    apply_robust_scaler: bool = True  # whether to apply robust scaling to the neural data\n",
        "    tmin: float = -.5\n",
        "    tmax: float = 1.\n",
        "\n",
        "    def prepare_neuro(self, session: str) -> mne.io.Raw:\n",
        "\n",
        "        \"\"\" Load the raw neuro data and filter \"\"\"\n",
        "\n",
        "        file = Path(self.preproc_path) / f\"{session}_preproc.fif\"\n",
        "\n",
        "        if file.exists():\n",
        "            raw = mne.io.read_raw(file, verbose=\"ERROR\")\n",
        "\n",
        "        else:\n",
        "            fmin = self.fmin\n",
        "            fmax = self.fmax\n",
        "            freq = self.freq\n",
        "\n",
        "            original_file = self.preproc_path / f\"{session}.fif\" # original file\n",
        "            raw = mne.io.read_raw(original_file)\n",
        "            raw = raw.pick(picks=[\"meg\"]) # don't want to analyse misc\n",
        "\n",
        "            # band pass filter\n",
        "            raw = raw.filter(fmin, fmax)\n",
        "\n",
        "            # downsample\n",
        "            if freq != raw.info[\"sfreq\"]:\n",
        "                raw = raw.resample(freq)\n",
        "\n",
        "        return raw\n",
        "\n",
        "    def __call__(self, session: str) -> tuple[np.ndarray, list[str]]:\n",
        "        \"\"\" Segment the neural data around words \"\"\"\n",
        "\n",
        "        raw = self.prepare_neuro(session)\n",
        "\n",
        "        if self.apply_robust_scaler:\n",
        "            raw.load_data()\n",
        "            raw._data = RobustScaler().fit_transform(raw._data.T).T\n",
        "\n",
        "        events = pd.read_csv(self.preproc_path / \"events.csv\")\n",
        "\n",
        "        # Select the words in the relevant session\n",
        "        words = events[(events['type'] == 'Word') & (events['session'] == session)].dropna().reset_index(drop=True)\n",
        "\n",
        "        # Get word onsets in samples\n",
        "        word_onsets = np.ones((len(words), 3), dtype=int) # mne.epochs expects events of shape (n_events, 3) but we are only interested in the first column here -> set the rest to 0\n",
        "        word_onsets[:, 0] = words.start *raw.info[\"sfreq\"] # first column must contain the onset of each event (word) in samples\n",
        "\n",
        "        # Segment\n",
        "        segments = mne.Epochs(\n",
        "            raw,\n",
        "            word_onsets,\n",
        "            metadata=words,\n",
        "            event_repeated=\"drop\",\n",
        "            baseline=(self.tmin, 0),  # setting a baseline (-0.2, 0) can improve decoding results. Baselining subtracts the mean value over this window from the entire segment.\n",
        "            tmin=self.tmin,\n",
        "            tmax=self.tmax,\n",
        "            verbose=\"ERROR\"\n",
        "        )\n",
        "        del raw\n",
        "\n",
        "        # from mne to numpy\n",
        "        words = segments.metadata['text']\n",
        "        neuro_array = segments.get_data(verbose=\"ERROR\").astype(np.float32)\n",
        "        del segments\n",
        "\n",
        "        # clip segments to prevent outliers impacting regression\n",
        "        neuro_array = np.clip(neuro_array, a_min=-20, a_max=20)\n",
        "\n",
        "        n_words, n_channels, n_times = neuro_array.shape\n",
        "\n",
        "        return neuro_array, words\n",
        "\n",
        "\n",
        "class Feature(pydantic.BaseModel):\n",
        "    model_config = pydantic.ConfigDict(extra=\"forbid\")\n",
        "\n",
        "    feature: tp.Literal['zipf_frequency', 'word_embedding']\n",
        "    _model = None\n",
        "\n",
        "    infra: MapInfra = MapInfra(version=\"v1\")\n",
        "\n",
        "    def model_post_init(self, __context):\n",
        "        if self.feature == \"word_embedding\":\n",
        "            try:\n",
        "                spacy.load(\"en_core_web_lg\")  # Ensure the spaCy model is loaded\n",
        "            except OSError:\n",
        "                spacy.cli.download(\"en_core_web_lg\")  # Ensure the spaCy model is downloaded\n",
        "\n",
        "    @infra.apply(item_uid=lambda x: str(x))\n",
        "    def embed(self, words: list[str]) -> tp.Iterator[np.array]:\n",
        "        if self._model is None:\n",
        "            self._model = spacy.load(\"en_core_web_lg\")\n",
        "        for word in words:\n",
        "            yield self._model(word).vector.astype(np.float32)\n",
        "\n",
        "\n",
        "class Data(pydantic.BaseModel):\n",
        "    model_config = pydantic.ConfigDict(extra=\"forbid\")\n",
        "\n",
        "    neuro: Neuro\n",
        "    feature: Feature\n",
        "    n_sessions: int = 1\n",
        "\n",
        "    def __call__(self) -> tuple[np.ndarray, np.ndarray]:\n",
        "\n",
        "        \"\"\" concatenate neural data and feature over multiple sessions \"\"\"\n",
        "\n",
        "        # get data\n",
        "        neuro_array = []\n",
        "        words = []\n",
        "\n",
        "        print(\"Preparing neuro\")\n",
        "        sessions = [i.name.split(\"_preproc\")[0] for i in sorted(list(self.neuro.preproc_path.glob(\"*.fif\")))] # neuro files available in path\n",
        "        if self.n_sessions > len(sessions):\n",
        "            raise ValueError(f\"You requested {self.n_sessions} but there are only {len(sessions)} available.\")\n",
        "\n",
        "        for session in sessions[:self.n_sessions]:\n",
        "            session_neuro_array, session_words = self.neuro(session)\n",
        "            neuro_array.append(session_neuro_array)\n",
        "            words.extend(session_words)\n",
        "        neuro_array = np.concatenate(neuro_array, 0)\n",
        "\n",
        "        # compute embedding\n",
        "        print(\"Preparing feature\")\n",
        "        feature_array = np.vstack(list(self.feature.embed(words)))  # (n_words, n_dims)\n",
        "\n",
        "        return neuro_array, feature_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyCxppoUQhrM"
      },
      "source": [
        "## 1. Building the dataloaders\n",
        "\n",
        "We start by loading the preprocessed MEG windows and word embeddings from the LibriBrain dataset, using the `Data` class defined in part 1.\n",
        "\n",
        "NOTE: For the purpose of this tutorial, we only make available (and load) a part of the entire LibriBrain dataset (3 sessions out of 92). Loading more recordings will likely improve results, though will take more time at the data preparation and model training steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXj2Mmg0QhrM"
      },
      "outputs": [],
      "source": [
        "data_config = {\n",
        "    \"neuro\": {\n",
        "        \"preproc_path\": DATA_DIR,\n",
        "        \"tmin\": -0.2,\n",
        "        \"tmax\": 1.8 - 1/80,\n",
        "        \"apply_robust_scaler\": True,\n",
        "    },\n",
        "    \"feature\": {\n",
        "        \"feature\": \"word_embedding\",\n",
        "        \"infra\": {\n",
        "            \"folder\": CACHE_DIR,\n",
        "        },\n",
        "    },\n",
        "    \"n_sessions\": 4,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxWITGyLQhrM",
        "outputId": "5a38e9d7-8c75-4995-81c5-3060b54ba86c"
      },
      "outputs": [],
      "source": [
        "# Get neuro and word data (~75 s to run)\n",
        "X, y = Data(**data_config)()\n",
        "\n",
        "print(f\"\\nData shape\\nX: {X.shape}\\ny: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6FKNrraQhrM"
      },
      "source": [
        "Now that we have our windowed data, we can split it into the different sets that are needed for modeling:\n",
        "(1) the training set is used to learn the parameters of our deep learning model,\n",
        "(2) the validation set is used to monitor the training process and decide when to stop it, and\n",
        "(3) the test set is used to provide an estimate of the generalization performance of our model.\n",
        "\n",
        "Here, we use the last 10% of windows for testing, and split the remaining 90% of windows into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXwrbqYcKOhh"
      },
      "outputs": [],
      "source": [
        "# Prepare dataloaders\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "valid_split_ratio = 0.1\n",
        "test_split_ratio = 0.1\n",
        "random_state = 42\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "\n",
        "# Split into train/valid/test\n",
        "inds = np.arange(X.shape[0])\n",
        "inds_train, inds_test = train_test_split(\n",
        "    inds, shuffle=False, test_size=test_split_ratio,\n",
        ")\n",
        "inds_train, inds_valid  = train_test_split(\n",
        "    inds_train,\n",
        "    shuffle=True,\n",
        "    test_size=valid_split_ratio / (1 - test_split_ratio),\n",
        "    random_state=random_state,\n",
        ")\n",
        "\n",
        "X_train, X_valid, X_test = X[inds_train], X[inds_valid], X[inds_test]\n",
        "y_train, y_valid, y_test = y[inds_train], y[inds_valid], y[inds_test]\n",
        "del X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdkJQiTeQhrM"
      },
      "source": [
        "We standardize the word embeddings to have zero mean and unit variance, which is a common practice in machine learning to ensure that all features contribute equally to the model training and stabilize training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4-X9IVyQhrM"
      },
      "outputs": [],
      "source": [
        "# Normalize targets\n",
        "target_scaler = StandardScaler()\n",
        "y_train = target_scaler.fit_transform(y_train)\n",
        "y_valid = target_scaler.transform(y_valid)\n",
        "y_test = target_scaler.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe7ONgC6QhrM"
      },
      "source": [
        "Finally, we create pytorch `DataLoader`s, which will be used to feed the data to the model during training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIL4-0NQhrN",
        "outputId": "d0d2af0f-e913-4887-9664-48f5d13f699e"
      },
      "outputs": [],
      "source": [
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "valid_dataset = TensorDataset(torch.tensor(X_valid), torch.tensor(y_valid))\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "print(\"Number of examples in each split\")\n",
        "print(f\"Train:\\t{len(train_dataset)}\")\n",
        "print(f\"Valid:\\t{len(valid_dataset)}\")\n",
        "print(f\"Test:\\t{len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3JjNTe0QhrN"
      },
      "source": [
        "## 2. Building the deep learning model\n",
        "\n",
        "In this section, we will define our deep learning architecture.\n",
        "\n",
        "We will use the residual dilated convolutional neural network of [D√©fossez et al. (2023)](https://www.nature.com/articles/s42256-023-00714-5). It performed well on multiple other M/EEG decoding tasks, e.g. [image decoding ](https://arxiv.org/abs/2310.19812), [word decoding](https://arxiv.org/abs/2412.17829) and [typing decoding](https://arxiv.org/abs/2502.17480).\n",
        "\n",
        "Following the formulation of part 1, we have:\n",
        "\n",
        "$y_{pred} = f_{\\Theta}(X) $ \\\n",
        "$R = corr(y, y_{pred})$\n",
        "\n",
        "where:\n",
        "- $X$ is the neuro segments, of shape `(n_examples, n_channels, n_times)`;\n",
        "- $y$ is the word embeddings, of shape `(n_examples, n_dims)`;\n",
        "- $\\Theta$ are the parameters of our convolutional network, to be tuned during training.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "The following implementation is a simplified version of the [original version](https://github.com/facebookresearch/brainmagick/blob/main/bm/models/simpleconv.py#L22), in which we drop less critical features and hardcode some hyperparameters to simplify this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XTeMSwYEQhrN"
      },
      "outputs": [],
      "source": [
        "#@title ‚ñ∂Ô∏è Run this first to define the model class\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class ConvSequence(nn.Module):\n",
        "    \"\"\"Sequence of residual, dilated convolutional layers with GLU activation.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: list[int],\n",
        "        kernel_size: int = 4,\n",
        "        dilation_growth: int = 2,\n",
        "        dilation_period: int = 5,\n",
        "        glu: int = 2,\n",
        "        glu_context: int = 1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if dilation_growth > 1:\n",
        "            assert kernel_size % 2 != 0, \"Supports only odd kernel with dilation for now\"\n",
        "\n",
        "        self.sequence = nn.ModuleList()\n",
        "        self.glus = nn.ModuleList()\n",
        "\n",
        "        dilation = 1\n",
        "        for k, (chin, chout) in enumerate(zip(channels[:-1], channels[1:])):\n",
        "            layers: list[nn.Module] = []\n",
        "\n",
        "            # conv layer\n",
        "            if dilation_period and (k % dilation_period) == 0:\n",
        "                dilation = 1\n",
        "\n",
        "            layers.extend([\n",
        "                nn.Conv1d(\n",
        "                    chin,\n",
        "                    chout,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=kernel_size // 2 * dilation,\n",
        "                    dilation=dilation,\n",
        "                    groups=1,\n",
        "                ),\n",
        "                nn.BatchNorm1d(num_features=chout),\n",
        "                nn.GELU(),\n",
        "            ])\n",
        "            dilation *= dilation_growth\n",
        "\n",
        "            self.sequence.append(nn.Sequential(*layers))\n",
        "            if (k + 1) % glu == 0:\n",
        "                self.glus.append(\n",
        "                    nn.Sequential(\n",
        "                        nn.Conv1d(chout, 2 * chout, 1 + 2 * glu_context, padding=glu_context),\n",
        "                        nn.GLU(dim=1),\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                self.glus.append(None)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        for ind, module in enumerate(self.sequence):\n",
        "            x = x + module(x)\n",
        "            if self.glus[ind] is not None:\n",
        "                x = self.glus[ind](x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SimpleConv(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        hidden: int = 320,\n",
        "        depth: int = 4,\n",
        "        kernel_size: int = 3,\n",
        "        growth: float = 1.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert kernel_size % 2 == 1, \"For padding to work, this must be verified\"\n",
        "        self.input_linear = nn.Conv1d(in_channels, hidden, 1)\n",
        "\n",
        "        # Build sequence of convolutional layers\n",
        "        sizes = [hidden] + [\n",
        "            int(round(hidden * growth**k)) for k in range(depth)\n",
        "        ]\n",
        "        self.encoder = ConvSequence(\n",
        "            sizes, kernel_size=kernel_size,\n",
        "        )\n",
        "\n",
        "        # Temporal aggregation\n",
        "        self.time_aggregation = nn.LazyLinear(1)\n",
        "        self.output_linear = nn.Linear(hidden, out_channels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # B, C, T = x.shape\n",
        "        x = self.input_linear(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.time_aggregation(x).squeeze(-1)  # (B, F, 1) -> (B, F)\n",
        "        x = self.output_linear(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C4zgcDyQhrN"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "pl.seed_everything(42)\n",
        "model = SimpleConv(\n",
        "    in_channels=X_train.shape[1],\n",
        "    out_channels=y_train.shape[1],\n",
        "    hidden=320,  # Number of hidden dimensions\n",
        "    depth=4,  # Number of convolutional layers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6AKlB_EQhrN"
      },
      "source": [
        "Let's print a summary of the model to see its architecture and number of parameters $\\Theta$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hel0NXhoQhrN",
        "outputId": "68884bd5-adbe-4cb4-b9e9-06ce4e3d775b"
      },
      "outputs": [],
      "source": [
        "# Print model summary\n",
        "from torchinfo import summary\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "input_data = {\"x\": batch[0][[0]]}\n",
        "summary(model, input_data=input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05navVCcQhrN"
      },
      "source": [
        "## 3. Preparing the training loop\n",
        "\n",
        "Two critical pieces of the training process are the optimizer and the loss function.\n",
        "\n",
        "The *optimizer* implements the parameter update procedure. Here, we use AdamW, a popular adaptive gradient descent optimizer for deep neural networks.\n",
        "\n",
        "The *loss function* is used to measure how well the neural network performs on an example. For simplicity, here we use the *mean squared error loss*:\n",
        "\n",
        "$\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{D}(y_{true}^{(i,j)}-y_{pred}^{(i,j)})^2$\n",
        "\n",
        "[TODO: Fix formulation of objective function]\n",
        "\n",
        "Here, we use [Pytorch Lightning](https://lightning.ai/docs/pytorch) to simplify the creation of these different elements. Pytorch Lightning is a wrapper around `torch` that provides a framework and utilities to easily train and evaluate deep learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acB9LWnkQhrN"
      },
      "outputs": [],
      "source": [
        "import lightning as pl\n",
        "\n",
        "class BrainModule(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        loss_fn: nn.Module,\n",
        "        learning_rate: float,\n",
        "        weight_decay: float,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def configure_optimizers(self) -> nn.Module:\n",
        "        return torch.optim.AdamW(\n",
        "            self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict_step(\n",
        "        self, batch, batch_idx: int, dataloader_idx: int = 0,\n",
        "    ) -> torch.Tensor:\n",
        "        return self.forward(batch[0])\n",
        "\n",
        "    def _run_step(self, batch) -> torch.Tensor:\n",
        "        x, y_true = batch\n",
        "        y_pred = self.forward(x)\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "\n",
        "    def training_step(\n",
        "        self, batch, batch_idx: int,\n",
        "    ) -> torch.Tensor:\n",
        "        loss = self._run_step(batch)\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
        "        loss = self._run_step(batch)\n",
        "        self.log(\"valid_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
        "        loss = self._run_step(batch)\n",
        "        self.log(\"test_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhfDxmyiQhrN"
      },
      "source": [
        "We define our lightning module with some default parameters (we will look into changing these later):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWvne5sRQhrN"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "module = BrainModule(\n",
        "    model=copy.deepcopy(model),\n",
        "    loss_fn=nn.MSELoss(),\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaH6yZJOQhrN"
      },
      "source": [
        "Next, we create a `Trainer`, which will handle the training loop.\n",
        "\n",
        "We include two callbacks, one for *early stopping*, and one for *model checkpointing*. The `patience` hyperparameter controls how many epochs we will wait for before stopping the training process if there is no improvement on the validation set. The best model according to validation set performance will be saved, and then reloaded for final evaluation on the test set.\n",
        "\n",
        "Of note, the maxmium number of training epochs (or \"passes\" through the training set) is set with `max_epochs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7ZV2Vl8QhrN",
        "outputId": "5cf21368-8f2a-41dd-af5b-39b572ad53ce"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "logger = CSVLogger(RESULTS_DIR / \"logs\", name=\"word_decoding\")\n",
        "\n",
        "# Create callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"valid_loss\",\n",
        "        min_delta=0.00,\n",
        "        patience=3,\n",
        "        mode=\"min\",\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        filename=\"best\",\n",
        "        monitor=\"valid_loss\",\n",
        "        mode=\"min\",\n",
        "        save_top_k=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=6,\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=callbacks,\n",
        "    logger=logger,\n",
        "    num_sanity_val_steps=0,  # Turn off sanity checking of validation dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y1E_voMQhrN"
      },
      "source": [
        "## 4. Training the model\n",
        "\n",
        "We can now launch our training loop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978,
          "referenced_widgets": [
            "eafedff516be4ecb81c41b6349e9a2c4",
            "3aa07c851a3d4fcb98ef7a7332d4a548",
            "b72d4cc61b6149cb9c7481796c592022",
            "1e9ab7de172840cc9bc34508f49b0329",
            "e30b8e0a58da41e4bc9aaa372b7bd768",
            "d25dc0e202f242faa582c98479b4312a",
            "c0f04c62d83d40ddbf81d904b373bf41",
            "0520c7dd88d64b91a94567dc957de7bc",
            "c70b8c95096a4a028df0c5d3cfcb83d3",
            "263415d230ec4dce86fa06f43a463ab9",
            "69bbfcc7b3084ef7a6454845dda3f9ea"
          ]
        },
        "id": "_2eEbAmZQhrO",
        "outputId": "50b8dc4b-f684-49b3-99c8-07e63fda0ea9"
      },
      "outputs": [],
      "source": [
        "# Takes about 25 s per epoch, e.g. 3.5 min for 8 epochs\n",
        "trainer.fit(\n",
        "    model=module,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=valid_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMEf-NXcQhrO"
      },
      "source": [
        "Next, we visualize the results of our training.\n",
        "\n",
        "The *learning curves* show how the loss evolved across training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMm7Y5uqQhrO"
      },
      "outputs": [],
      "source": [
        "# Load the logged metrics\n",
        "log_output_df = pd.read_csv(Path(logger.log_dir) / \"metrics.csv\")\n",
        "log_output_df = log_output_df.melt(\n",
        "    id_vars=[\"epoch\"],\n",
        "    value_vars=[\"train_loss\", \"valid_loss\"],\n",
        "    var_name=\"split\",\n",
        "    value_name=\"loss\",\n",
        ").dropna(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "QJU_RKaHQhrO",
        "outputId": "0dd4d454-42cf-4baf-ec16-ac0415b659d6"
      },
      "outputs": [],
      "source": [
        "# Plot them\n",
        "import seaborn as sns\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "sns.lineplot(\n",
        "    data=log_output_df,\n",
        "    x=\"epoch\",\n",
        "    y=\"loss\",\n",
        "    hue=\"split\",\n",
        "    marker=\"o\",\n",
        "    markersize=5,\n",
        "    linewidth=1,\n",
        "    ax=ax,\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV-YEfm0QhrO"
      },
      "source": [
        "Generally, we expect the training loss to steadily decrease from epoch to epoch, and the validation loss to initially decrease, and then eventually start increasing (i.e. the model enters the \"overfitting\" regime)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT9Ssp6EQhrO"
      },
      "source": [
        "## 5. Evaluate test performance\n",
        "\n",
        "As we did in part 1, we can also measure the performance of our model on a test set which was not seen during training (i.e. \"held-out\"). This gives us an estimate of the generalization performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "288017e36e7f4e72b0ae81e6d7516400",
            "e73bec2233644b62ab8a72a6a61f23b1",
            "3b454fbbcb174d20a73acb0e7922223f",
            "0d71c14ce13f4142b121736a4e47850b",
            "1b48e858cf3a47f886bb63c9fdb2c2a7",
            "89a3f971a7314c29a8893d4a154d1911",
            "f746eded85824931b520d309177f6c2b",
            "b45df3994d56408fab3c9116990dddcf",
            "30fe72d3cf4d4358ba64b73a7becc2a1",
            "1bfa0abbfb724714ad9cfb8006df7e83",
            "a1149afafcbf4eebb4600cea07e5d65f"
          ]
        },
        "id": "U0XdAPJnQhrO",
        "outputId": "239c5b17-4d07-42b8-b3d0-99f9c2701c6e"
      },
      "outputs": [],
      "source": [
        "y_true = torch.concat([batch[1] for batch in test_dataloader], dim=0)\n",
        "y_pred = torch.concat(trainer.predict(dataloaders=test_dataloader), dim=0)\n",
        "\n",
        "assert y_pred.shape == y_true.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "lpTduPEaQhrO",
        "outputId": "64e1d7b2-879a-4c81-8ce3-c23a69485437"
      },
      "outputs": [],
      "source": [
        "# Compute Pearson correlation\n",
        "corr = pearsonr(y_true, y_pred, axis=0).statistic\n",
        "\n",
        "ax = sns.histplot(corr, bins=50)\n",
        "ax.axvline(\n",
        "    corr.mean(),\n",
        "    color=\"tab:red\",\n",
        "    linestyle=\"--\",\n",
        "    label=f\"Mean R: {corr.mean():0.3f}\",\n",
        ")\n",
        "ax.set_xlabel(\"Pearson R\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc_gyvvcQhrO"
      },
      "source": [
        "[Add some kind of conclusion]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrd09u1CQhrS"
      },
      "source": [
        "## 6. Putting everything together into an `Experiment` class\n",
        "\n",
        "Finally, as we did in part 1, we can leverage `exca` to structure the entire pipeline into a single configurable class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYR2moZiQhrS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "\n",
        "class DeepDecodingExperiment(pydantic.BaseModel):\n",
        "    data: Data\n",
        "\n",
        "    # Splits\n",
        "    valid_split_ratio: float = 0.1\n",
        "    test_split_ratio: float = 0.1\n",
        "    split_random_state: int | None = 42\n",
        "\n",
        "    # Dataloaders\n",
        "    batch_size: int = 128\n",
        "    num_workers: int = 10\n",
        "\n",
        "    # Model\n",
        "    seed: int | None = None\n",
        "\n",
        "    # Optimization\n",
        "    loss_name: tp.Literal[\"mse\", \"clip\"] = \"mse\"\n",
        "    learning_rate: float = 3e-4\n",
        "    weight_decay: float = 0.01\n",
        "    n_epochs: int = 10\n",
        "    patience: int = 3\n",
        "\n",
        "    # exca\n",
        "    infra: TaskInfra = TaskInfra()\n",
        "\n",
        "    def _prepare_loaders(self, X: np.ndarray, y: np.ndarray) -> list[DataLoader]:\n",
        "        \"\"\"Prepare dataloaders.\"\"\"\n",
        "\n",
        "        # Split into train/valid/test\n",
        "        X_train, X_test, y_train, y_test  = train_test_split(\n",
        "            X,\n",
        "            y,\n",
        "            shuffle=False,\n",
        "            test_size=self.test_split_ratio,\n",
        "            # random_state=self.split_random_state,\n",
        "        )\n",
        "        X_train, X_valid, y_train, y_valid  = train_test_split(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            shuffle=True,\n",
        "            test_size=self.valid_split_ratio / (1 - self.test_split_ratio),\n",
        "            # random_state=self.split_random_state,\n",
        "        )\n",
        "\n",
        "        # Normalize targets\n",
        "        target_scaler = StandardScaler()\n",
        "        y_train = target_scaler.fit_transform(y_train)\n",
        "        y_valid = target_scaler.transform(y_valid)\n",
        "        y_test = target_scaler.transform(y_test)\n",
        "\n",
        "        # Create datasets and dataloaders\n",
        "        train_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "        valid_dataset = TensorDataset(torch.tensor(X_valid).float(), torch.tensor(y_valid).float())\n",
        "        valid_dataloader = DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "        test_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "        print(\"Number of examples in each split\")\n",
        "        print(f\"Train:\\t{len(train_dataset)}\")\n",
        "        print(f\"Valid:\\t{len(valid_dataset)}\")\n",
        "        print(f\"Test:\\t{len(test_dataset)}\")\n",
        "\n",
        "        return train_dataloader, valid_dataloader, test_dataloader\n",
        "\n",
        "    def _prepare_model(self, in_channels: int, out_channels: int) -> SimpleConv:\n",
        "        return SimpleConv(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            hidden=320,\n",
        "            depth=4,\n",
        "            kernel_size=3,\n",
        "            growth=1.0,\n",
        "        )\n",
        "\n",
        "    def _prepare_trainer(self) -> pl.Trainer:\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor=\"valid_loss\",\n",
        "                min_delta=0.00,\n",
        "                patience=self.patience,\n",
        "                mode=\"min\",\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                filename=\"best\",\n",
        "                monitor=\"valid_loss\",\n",
        "                mode=\"min\",\n",
        "                save_top_k=1,\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        logger = CSVLogger(self.infra.uid_folder() / \"logs\", name=\"word_decoding\")\n",
        "\n",
        "        return pl.Trainer(\n",
        "            max_epochs=self.n_epochs,\n",
        "            accelerator=\"auto\",\n",
        "            callbacks=callbacks,\n",
        "            num_sanity_val_steps=0,  # Turn off sanity checking of validation dataloader\n",
        "            logger=logger,\n",
        "        )\n",
        "\n",
        "    def _evaluate_corr(self, trainer: pl.Trainer, test_loader: DataLoader) -> np.ndarray:\n",
        "        y_true = torch.concat([batch[1] for batch in test_loader], dim=0)\n",
        "        y_pred = torch.concat(trainer.predict(dataloaders=test_loader), dim=0)\n",
        "        return pearsonr(y_true, y_pred, axis=0).statistic\n",
        "\n",
        "    @infra.apply\n",
        "    def run(self) -> np.ndarray:\n",
        "        \"\"\"Fit and evaluate a deep decoding model.\"\"\"\n",
        "\n",
        "        print(f\"Decoding {self.data.feature.feature} from {self.data.n_sessions} sessions\")\n",
        "        X, y = self.data()\n",
        "        train_loader, valid_loader, test_loader = self._prepare_loaders(X, y)\n",
        "\n",
        "        # Prepare model\n",
        "        pl.seed_everything(self.seed)\n",
        "        model = self._prepare_model(X.shape[1], y.shape[1])\n",
        "\n",
        "        # Prepare pytorch lightning module\n",
        "        loss_fn = nn.MSELoss() if self.loss_name == \"mse\" else ClipLoss()\n",
        "        module = BrainModule(\n",
        "            model=model,\n",
        "            loss_fn=loss_fn,\n",
        "            learning_rate=self.learning_rate,\n",
        "            weight_decay=self.weight_decay,\n",
        "        )\n",
        "\n",
        "        # Prepare trainer\n",
        "        trainer = self._prepare_trainer()\n",
        "\n",
        "        print(\"Fitting model\")\n",
        "        trainer.fit(\n",
        "            model=module,\n",
        "            train_dataloaders=train_loader,\n",
        "            val_dataloaders=valid_loader\n",
        "        )\n",
        "\n",
        "        # Predict and evaluate performance\n",
        "        corr = self._evaluate_corr(trainer, test_loader)\n",
        "        print(f\"Test mean Pearson R: {corr.mean():0.3f}\")\n",
        "\n",
        "        return corr\n",
        "\n",
        "\n",
        "\n",
        "# --- BONUS - For contrastive learning with CLIP loss ---\n",
        "\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "class ClipLoss(nn.Module):\n",
        "    \"\"\"CLIP constrastive loss [1]_ with configuration from [2]_.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Radford, Alec, et al. \"Learning transferable visual models from natural language\n",
        "        supervision.\" International conference on machine learning. PMLR, 2021.\n",
        "    .. [2] D√©fossez, Alexandre, et al. \"Decoding speech perception from non-invasive brain\n",
        "        recordings.\" Nature Machine Intelligence (2023): 1-11.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def _compute_similarity(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "        inv_norms = 1 / (y.norm(dim=(1), p=2) + 1e-15)\n",
        "        return torch.einsum(\"bc,oc,o->bo\", x, y, inv_norms)\n",
        "\n",
        "    # XXX Change to y_pred, y_true\n",
        "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Warning: y_pred and y_true are not necessarily symmetrical.\n",
        "\n",
        "        If y_pred of shape [B, C] and y_true of shape [B', C] with B'>=B, the first B samples\n",
        "        of y_true are targets, while the remaining B'-B samples of y_true are only used as\n",
        "        negatives.\n",
        "        \"\"\"\n",
        "        scores = self._compute_similarity(y_pred, y_true)\n",
        "        target = torch.arange(len(scores), device=y_pred.device)\n",
        "\n",
        "        return cross_entropy(scores, target, reduction=\"mean\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unTARU7UQhrS"
      },
      "source": [
        "Our entire experiment can now be configured using a dictionary (let's make a version that will run quickly to start with):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_jXNPHRQhrS"
      },
      "outputs": [],
      "source": [
        "exp_config = {\n",
        "  \"data\": {\n",
        "      \"neuro\": {\n",
        "          \"preproc_path\": DATA_DIR,\n",
        "          \"tmin\": -0.2,\n",
        "          \"tmax\": 1.8 - 1/80,\n",
        "          \"apply_robust_scaler\": True,\n",
        "      },\n",
        "      \"feature\": {\n",
        "          \"feature\": \"word_embedding\",\n",
        "          \"infra\": {\n",
        "              \"folder\": CACHE_DIR,\n",
        "          },\n",
        "      },\n",
        "      \"n_sessions\": 2,\n",
        "  },\n",
        "  # Splitting\n",
        "  \"valid_split_ratio\": 0.1,\n",
        "  \"test_split_ratio\": 0.1,\n",
        "  \"split_random_state\": 42,\n",
        "  # Dataloaders\n",
        "  \"batch_size\": 128,\n",
        "  \"num_workers\": 10,\n",
        "  # Optimization\n",
        "  \"loss_name\": \"mse\",\n",
        "  \"learning_rate\": 3e-4,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"n_epochs\": 1,\n",
        "  \"patience\": 1,\n",
        "  # Exca\n",
        "  \"infra\": {\n",
        "      \"folder\": RESULTS_DIR,\n",
        "  },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN8F09FEQhrS"
      },
      "outputs": [],
      "source": [
        "exp = DeepDecodingExperiment(**exp_config)\n",
        "\n",
        "# Uncomment to run the experiment (will take some time and memory):\n",
        "# corr = exp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nhBkVzwQhrS"
      },
      "source": [
        "Of note, using `exca`, we can easily launch multiple versions of our experiment in parallel with a [SLURM array](https://slurm.schedmd.com/job_array.html).\n",
        "\n",
        "E.g., we could test the impact of different loss functions, batch sizes, learning rates and random seeds like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irU3-BpgQhrS"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from itertools import product\n",
        "from tqdm import tqdm\n",
        "\n",
        "loss_names = [\"mse\", \"clip\"]\n",
        "batch_sizes = [32, 64, 128]\n",
        "learning_rates = [3e-5, 3e-4, 3e-3]\n",
        "seeds = [33, 34, 35]\n",
        "\n",
        "task = DeepDecodingExperiment(**exp_config)\n",
        "with task.infra.job_array() as tasks:\n",
        "    for (\n",
        "        loss_name,\n",
        "        batch_size,\n",
        "        learning_rate,\n",
        "        seed\n",
        "    ) in tqdm(list(product(\n",
        "        loss_names,\n",
        "        batch_sizes,\n",
        "        learning_rates,\n",
        "        seeds,\n",
        "    )), \"Preparing tasks\"):\n",
        "        updated_config = deepcopy(exp_config)\n",
        "        updated_config[\"loss_name\"] = loss\n",
        "        updated_config[\"batch_size\"] = batch_size\n",
        "        updated_config[\"learning_rate\"] = learning_rate\n",
        "        updated_config[\"seed\"] = seed\n",
        "\n",
        "        task_ = DeepDecodingExperiment(**updated_config)\n",
        "\n",
        "        # Uncomment this line on a SLURM cluster to launch all jobs as a SLURM array:\n",
        "        # tasks.append(task_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PiC09GZQhrS"
      },
      "source": [
        "## Going further\n",
        "\n",
        "This is it for part 3 of this tutorial! üéâ\n",
        "\n",
        "üîß To improve the *flexibility of our pipeline*, next steps may include:\n",
        "- Further expose components as configurable Pydantic objects (e.g. deep learning architecture, loss functions, etc.)\n",
        "- Monitor performance metrics during training using [TorchMetrics](https://lightning.ai/docs/torchmetrics/)\n",
        "- Log results to a live visualization platform, e.g. [Weights & Biases](https://wandb.ai/) or [Tensorboard](https://www.tensorflow.org/tensorboard)\n",
        "\n",
        "üìà To improve *performance*, next steps may include:\n",
        "- Including more recordings into our training dataset\n",
        "- Improving the architecture (deeper/wider, handling channel positions, word-level modelling, etc.)\n",
        "- Optimizing the hyperparameters (learning rate, batch size, etc.).\n",
        "\n",
        "Have fun!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0520c7dd88d64b91a94567dc957de7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d71c14ce13f4142b121736a4e47850b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bfa0abbfb724714ad9cfb8006df7e83",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a1149afafcbf4eebb4600cea07e5d65f",
            "value": "‚Äá12/12‚Äá[00:00&lt;00:00,‚Äá22.39it/s]"
          }
        },
        "1b48e858cf3a47f886bb63c9fdb2c2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1bfa0abbfb724714ad9cfb8006df7e83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9ab7de172840cc9bc34508f49b0329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263415d230ec4dce86fa06f43a463ab9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_69bbfcc7b3084ef7a6454845dda3f9ea",
            "value": "‚Äá2/152‚Äá[00:15&lt;19:39,‚Äá‚Äá0.13it/s,‚Äáv_num=0]"
          }
        },
        "263415d230ec4dce86fa06f43a463ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288017e36e7f4e72b0ae81e6d7516400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e73bec2233644b62ab8a72a6a61f23b1",
              "IPY_MODEL_3b454fbbcb174d20a73acb0e7922223f",
              "IPY_MODEL_0d71c14ce13f4142b121736a4e47850b"
            ],
            "layout": "IPY_MODEL_1b48e858cf3a47f886bb63c9fdb2c2a7"
          }
        },
        "30fe72d3cf4d4358ba64b73a7becc2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aa07c851a3d4fcb98ef7a7332d4a548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d25dc0e202f242faa582c98479b4312a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c0f04c62d83d40ddbf81d904b373bf41",
            "value": "Epoch‚Äá0:‚Äá‚Äá‚Äá1%"
          }
        },
        "3b454fbbcb174d20a73acb0e7922223f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45df3994d56408fab3c9116990dddcf",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30fe72d3cf4d4358ba64b73a7becc2a1",
            "value": 12
          }
        },
        "69bbfcc7b3084ef7a6454845dda3f9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89a3f971a7314c29a8893d4a154d1911": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1149afafcbf4eebb4600cea07e5d65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b45df3994d56408fab3c9116990dddcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72d4cc61b6149cb9c7481796c592022": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0520c7dd88d64b91a94567dc957de7bc",
            "max": 152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c70b8c95096a4a028df0c5d3cfcb83d3",
            "value": 2
          }
        },
        "c0f04c62d83d40ddbf81d904b373bf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c70b8c95096a4a028df0c5d3cfcb83d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d25dc0e202f242faa582c98479b4312a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30b8e0a58da41e4bc9aaa372b7bd768": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e73bec2233644b62ab8a72a6a61f23b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a3f971a7314c29a8893d4a154d1911",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f746eded85824931b520d309177f6c2b",
            "value": "Predicting‚ÄáDataLoader‚Äá0:‚Äá100%"
          }
        },
        "eafedff516be4ecb81c41b6349e9a2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aa07c851a3d4fcb98ef7a7332d4a548",
              "IPY_MODEL_b72d4cc61b6149cb9c7481796c592022",
              "IPY_MODEL_1e9ab7de172840cc9bc34508f49b0329"
            ],
            "layout": "IPY_MODEL_e30b8e0a58da41e4bc9aaa372b7bd768"
          }
        },
        "f746eded85824931b520d309177f6c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
